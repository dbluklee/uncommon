"""
ê°œì„ ëœ Milvus ë²¡í„° ìŠ¤í† ì–´ ëª¨ë“ˆ
ë ˆí¼ëŸ°ìŠ¤ ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ IP ë©”íŠ¸ë¦­ê³¼ HNSW ì¸ë±ìŠ¤ ìµœì í™”
"""

import os
import logging
from typing import List, Dict, Any, Optional
from pymilvus import Collection, connections, utility
from langchain_core.documents import Document
from langchain.vectorstores.base import VectorStore

logger = logging.getLogger(__name__)

class ImprovedMilvusVectorStore(VectorStore):
    """ê°œì„ ëœ Milvus ë²¡í„° ìŠ¤í† ì–´ - ë ˆí¼ëŸ°ìŠ¤ ì½”ë“œ ê¸°ë°˜"""
    
    def __init__(self, 
                 collection_name: str,
                 embedding_model,
                 metric_type: str = None,
                 index_type: str = None,
                 milvus_host: str = None,
                 milvus_port: str = None):
        """
        Args:
            collection_name: Milvus ì»¬ë ‰ì…˜ ì´ë¦„
            embedding_model: ìž„ë² ë”© ìƒì„± ëª¨ë¸
            metric_type: ë©”íŠ¸ë¦­ íƒ€ìž… (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìžë™ ë¡œë“œ)
            index_type: ì¸ë±ìŠ¤ íƒ€ìž… (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìžë™ ë¡œë“œ)
            milvus_host: Milvus í˜¸ìŠ¤íŠ¸ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìžë™ ë¡œë“œ)
            milvus_port: Milvus í¬íŠ¸ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìžë™ ë¡œë“œ)
        """
        self.collection_name = collection_name
        self.embedding_model = embedding_model
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
        self.metric_type = metric_type or os.environ.get("METRIC_TYPE", "IP")
        self.index_type = index_type or os.environ.get("INDEX_TYPE", "HNSW")
        self.milvus_host = milvus_host or os.environ["MILVUS_HOST"]
        self.milvus_port = milvus_port or os.environ["MILVUS_INTERNAL_PORT"]
        
        # Milvus ì—°ê²°
        self._connect_milvus()
        
        # ì»¬ë ‰ì…˜ ë¡œë“œ
        self._load_collection()
    
    def _connect_milvus(self):
        """Milvus ì„œë²„ ì—°ê²°"""
        try:
            logger.info(f"ðŸ”— Milvus ì—°ê²° ì‹œë„: {self.milvus_host}:{self.milvus_port}")
            
            connections.connect(
                alias="default",
                host=self.milvus_host,
                port=self.milvus_port,
                timeout=30
            )
            
            # ì„œë²„ ë²„ì „ ì •ë³´ë¡œ ì—°ê²° í™•ì¸
            server_version = utility.get_server_version()
            logger.info(f"âœ… Milvus ì—°ê²° ì„±ê³µ! (ì„œë²„ ë²„ì „: {server_version})")
            
        except Exception as e:
            logger.error(f"âŒ Milvus ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _load_collection(self):
        """ì»¬ë ‰ì…˜ ë¡œë“œ"""
        try:
            if not utility.has_collection(self.collection_name):
                logger.error(f"ì»¬ë ‰ì…˜ '{self.collection_name}'ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                raise ValueError(f"Collection '{self.collection_name}' not found")
            
            self.collection = Collection(name=self.collection_name)
            self.collection.load()
            
            # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
            total_docs = self.collection.num_entities
            logger.info(f"ðŸ“Š ì»¬ë ‰ì…˜ ì´ ë¬¸ì„œ ìˆ˜: {total_docs}")
            logger.info(f"âœ… ì»¬ë ‰ì…˜ '{self.collection_name}' ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _get_search_params(self) -> Dict[str, Any]:
        """ì¸ë±ìŠ¤ íƒ€ìž…ì— ë”°ë¥¸ ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ë°˜í™˜"""
        if self.index_type == 'HNSW':
            params = {"ef": 64}
        elif self.index_type in ["IVF_FLAT", "IVF_SQ8", "IVF_PQ"]:
            params = {"nprobe": 10}
        else:
            params = {}
        
        return {
            "metric_type": self.metric_type,
            "params": params
        }
    
    def similarity_search(self, query: str, k: int = 4, **kwargs) -> List[Document]:
        """
        ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ (LangChain ì¸í„°íŽ˜ì´ìŠ¤)
        ë ˆí¼ëŸ°ìŠ¤ ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ ê°œì„ 
        """
        # ì»¬ë ‰ì…˜ ì´ ë¬¸ì„œ ìˆ˜ í™•ì¸
        self.collection.load()
        total_docs = self.collection.num_entities
        logger.info(f"ðŸ“Š ì»¬ë ‰ì…˜ ì´ ë¬¸ì„œ ìˆ˜: {total_docs}")
        logger.info(f"ðŸ“Š ìš”ì²­ëœ k ê°’: {k}")
        
        # ì‹¤ì œ k ê°’ ì¡°ì •
        actual_k = min(k, total_docs)
        logger.info(f"ðŸ“Š ì‹¤ì œ ê²€ìƒ‰í•  k ê°’: {actual_k}")
        
        if total_docs == 0:
            logger.warning("âš ï¸ ì»¬ë ‰ì…˜ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!")
            return []
        
        # ì¿¼ë¦¬ ìž„ë² ë”© ìƒì„±
        logger.info(f"ðŸ” ì¿¼ë¦¬ ìž„ë² ë”© ìƒì„±: '{query[:50]}...'")
        query_vector = self.embedding_model.generate_query_embedding(query)
        logger.info(f"ðŸ“ ì¿¼ë¦¬ ë²¡í„° ì°¨ì›: {len(query_vector)}")
        
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •
        search_params = self._get_search_params()
        logger.info(f"ðŸ”§ ê²€ìƒ‰ íŒŒë¼ë¯¸í„°:")
        logger.info(f"   - metric_type: {search_params['metric_type']}")
        logger.info(f"   - index_type: {self.index_type}")
        logger.info(f"   - params: {search_params['params']}")
        logger.info(f"   - limit: {actual_k}")
        
        # ê²€ìƒ‰ ì‹¤í–‰
        logger.info("ðŸ” ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
        try:
            results = self.collection.search(
                data=[query_vector],
                anns_field="vector",
                param=search_params,
                limit=actual_k,
                output_fields=["product_id", "product_name", "chunk_type", "source", "content"]
            )
            
            logger.info("âœ… ê²€ìƒ‰ ì™„ë£Œ!")
            logger.info(f"ðŸ“Š ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜: {len(results[0]) if results else 0}")
            
            # ê° ê²°ê³¼ì˜ ìƒì„¸ ì •ë³´ ì¶œë ¥
            if results and len(results[0]) > 0:
                for i, hit in enumerate(results[0]):
                    logger.info(f"   ê²°ê³¼ {i+1}: score={hit.score:.4f}, id={hit.id}")
                    logger.info(f"          product_name: {hit.entity.get('product_name', 'N/A')}")
                    logger.info(f"          content ê¸¸ì´: {len(hit.entity.get('content', ''))}")
            
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
        
        # LangChain Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        logger.info("ðŸ”„ LangChain Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
        docs = []
        for hits in results:
            for hit in hits:
                doc = Document(
                    page_content=hit.entity.get("content", ""),
                    metadata={
                        "product_id": hit.entity.get("product_id"),
                        "product_name": hit.entity.get("product_name"),
                        "chunk_type": hit.entity.get("chunk_type"),
                        "source": hit.entity.get("source"),
                        "score": hit.score,
                        "id": hit.id
                    }
                )
                docs.append(doc)
        
        logger.info(f"âœ… {len(docs)}ê°œ ë¬¸ì„œë¥¼ LangChain Documentë¡œ ë³€í™˜ ì™„ë£Œ")
        return docs
    
    def similarity_search_with_score(self, query: str, k: int = 4, **kwargs) -> List[tuple]:
        """ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰"""
        docs = self.similarity_search(query, k, **kwargs)
        return [(doc, doc.metadata.get('score', 0.0)) for doc in docs]
    
    def add_texts(self, texts: List[str], metadatas: Optional[List[dict]] = None, **kwargs) -> List[str]:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€ (ë¯¸êµ¬í˜„ - ì¸ë±ì‹± ì„œë¹„ìŠ¤ì—ì„œ ì²˜ë¦¬)"""
        logger.warning("í…ìŠ¤íŠ¸ ì¶”ê°€ëŠ” ì¸ë±ì‹± ì„œë¹„ìŠ¤ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤")
        return []
    
    def add_documents(self, documents: List[Document], **kwargs) -> List[str]:
        """Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€ (ë¯¸êµ¬í˜„ - ì¸ë±ì‹± ì„œë¹„ìŠ¤ì—ì„œ ì²˜ë¦¬)"""
        logger.warning("ë¬¸ì„œ ì¶”ê°€ëŠ” ì¸ë±ì‹± ì„œë¹„ìŠ¤ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤")
        return []

    @classmethod
    def from_texts(
        cls,
        texts: List[str],
        embedding_model,
        metadatas: Optional[List[dict]] = None,
        **kwargs
    ) -> "ImprovedMilvusVectorStore":
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ë²¡í„° ìŠ¤í† ì–´ ìƒì„± (ë¯¸êµ¬í˜„ - ì¸ë±ì‹± ì„œë¹„ìŠ¤ì—ì„œ ì²˜ë¦¬)"""
        logger.warning("from_textsëŠ” ì¸ë±ì‹± ì„œë¹„ìŠ¤ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ë¹ˆ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return cls(
            collection_name=kwargs.get("collection_name", "default"),
            embedding_model=embedding_model,
            **kwargs
        )
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            return {
                "collection_name": self.collection_name,
                "row_count": self.collection.num_entities,
                "loaded": True,
                "metric_type": self.metric_type,
                "index_type": self.index_type
            }
        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"error": str(e)}
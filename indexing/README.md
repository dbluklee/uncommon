# Indexing ì„œë¹„ìŠ¤

## ğŸ“‹ ê°œìš”
PostgreSQLì— ì €ì¥ëœ ì œí’ˆ ë°ì´í„°ë¥¼ BGE-M3 ì„ë² ë”© ëª¨ë¸ë¡œ ë²¡í„°í™”í•˜ì—¬ Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ì¸ë±ì‹± ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. CPUì™€ GPUë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ìµœì ì˜ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥
- **í…ìŠ¤íŠ¸ ì„ë² ë”©**: BGE-M3 ëª¨ë¸ì„ ì‚¬ìš©í•œ 1024ì°¨ì› ë²¡í„° ìƒì„±
- **í…ìŠ¤íŠ¸ ì²­í‚¹**: ì œí’ˆ ì •ë³´ë¥¼ ê²€ìƒ‰ì— ìµœì í™”ëœ ì²­í¬ë¡œ ë¶„í• 
- **ë²¡í„° ì €ì¥**: Milvus ë°ì´í„°ë² ì´ìŠ¤ì— ì„ë² ë”© ë²¡í„° ì €ì¥
- **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ì œí’ˆ ë°ì´í„°ì˜ íš¨ìœ¨ì ì¸ ì¼ê´„ ì²˜ë¦¬
- **CUDA ê°€ì†**: GPU ì‚¬ìš© ì‹œ ì„ë² ë”© ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### í™˜ê²½ë³€ìˆ˜
```bash
INDEXING_PORT=8002                  # ì™¸ë¶€ ì ‘ê·¼ í¬íŠ¸
INDEXING_INTERNAL_PORT=8000        # ì»¨í…Œì´ë„ˆ ë‚´ë¶€ í¬íŠ¸
EMBEDDING_MODEL=BAAI/bge-m3        # ì„ë² ë”© ëª¨ë¸
USE_CUDA=true                      # CUDA ì‚¬ìš© ì—¬ë¶€
CUDA_DEVICE=0                      # GPU ë””ë°”ì´ìŠ¤ ë²ˆí˜¸
DIMENSION=1024                     # ë²¡í„° ì°¨ì›
MAX_CONTEXT_LENGTH=4000           # ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´
```

### ì‹¤í–‰ ëª…ë ¹
```bash
# ì„œë¹„ìŠ¤ ì‹œì‘
cd indexing
source ../.env.global
docker compose up -d

# ë¡œì»¬ ê°œë°œ ì‹¤í–‰ (CUDA í™˜ê²½)
pip install -r requirements.txt
python main.py
```

### ì ‘ì† ì •ë³´
- **API ì„œë²„**: `http://localhost:8002`
- **Swagger UI**: `http://localhost:8002/docs`

## ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸

### 1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
```http
GET /
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
    "message": "Indexing Service is running",
    "embedding_model": "BAAI/bge-m3",
    "device": "cuda:0",
    "dimension": 1024
}
```

### 2. í—¬ìŠ¤ì²´í¬
```http
GET /health
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
    "status": "healthy",
    "service": "indexing",
    "model_loaded": true,
    "milvus_connected": true,
    "timestamp": "2024-01-10T10:30:00Z"
}
```

### 3. ì „ì²´ ì œí’ˆ ì¸ë±ì‹± (ë°±ê·¸ë¼ìš´ë“œ)
```http
POST /index/products
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
    "message": "ì¸ë±ì‹± ì‘ì—…ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
    "total_products": 150,
    "status": "started"
}
```

### 4. ì¸ë±ì‹± í†µê³„ ì¡°íšŒ
```http
GET /index/stats
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
    "total_products": 150,
    "indexed_products": 120,
    "pending_products": 30,
    "collection_info": {
        "name": "uncommon_products",
        "dimension": 1024,
        "metric_type": "COSINE",
        "entity_count": 120
    }
}
```

### 5. ê°œë³„ ì œí’ˆ ì¸ë±ì‹±
```http
POST /index/products/{product_id}
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
    "product_id": 123,
    "chunks_created": 3,
    "vectors_inserted": 3,
    "status": "completed"
}
```

### 6. ì œí’ˆ ì¸ë±ìŠ¤ ì‚­ì œ
```http
DELETE /index/products/{product_id}
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
    "product_id": 123,
    "vectors_deleted": 3,
    "status": "deleted"
}
```

## ğŸ“Š ì…ë ¥/ì¶œë ¥ ë°ì´í„° í˜•ì‹

### ì…ë ¥ ë°ì´í„° (PostgreSQLì—ì„œ ì¡°íšŒ)
```python
product_data = {
    "id": 123,
    "product_name": "UNCOMMON Titanium Frame",
    "color": "Black", 
    "price": {"global": "$199.00", "kr": "259,000ì›"},
    "description": {"global": "Premium titanium frame", "kr": "í”„ë¦¬ë¯¸ì—„ í‹°íƒ€ëŠ„ í”„ë ˆì„"},
    "material": {"global": "Titanium, Acetate", "kr": "í‹°íƒ€ëŠ„, ì•„ì„¸í…Œì´íŠ¸"},
    "size": {"global": "Medium (52-18-145)", "kr": "ë¯¸ë””ì—„ (52-18-145)"}
}
```

### í…ìŠ¤íŠ¸ ì²­í‚¹ ê²°ê³¼
```python
chunks = [
    {
        "chunk_id": 1,
        "text": "UNCOMMON Titanium Frame Black í”„ë¦¬ë¯¸ì—„ í‹°íƒ€ëŠ„ í”„ë ˆì„ ê³ ê¸‰ ì•„ì´ì›¨ì–´",
        "chunk_type": "product_name_description"
    },
    {
        "chunk_id": 2, 
        "text": "ì¬ì§ˆ: í‹°íƒ€ëŠ„, ì•„ì„¸í…Œì´íŠ¸ ê³ í’ˆì§ˆ ì†Œì¬ ê²½ëŸ‰ ë‚´êµ¬ì„±",
        "chunk_type": "material_features"
    },
    {
        "chunk_id": 3,
        "text": "ì‚¬ì´ì¦ˆ: ë¯¸ë””ì—„ (52-18-145) ê°€ê²©: $199.00 259,000ì›",
        "chunk_type": "size_price"
    }
]
```

### ë²¡í„° ìƒì„± ê²°ê³¼
```python
embeddings = [
    {
        "id": 1001,
        "product_id": 123,
        "text_content": "UNCOMMON Titanium Frame Black í”„ë¦¬ë¯¸ì—„ í‹°íƒ€ëŠ„ í”„ë ˆì„...",
        "embedding": [0.123, -0.456, 0.789, ..., 0.321]  # 1024ì°¨ì› ë²¡í„°
    },
    {
        "id": 1002,
        "product_id": 123, 
        "text_content": "ì¬ì§ˆ: í‹°íƒ€ëŠ„, ì•„ì„¸í…Œì´íŠ¸ ê³ í’ˆì§ˆ ì†Œì¬...",
        "embedding": [0.234, -0.567, 0.890, ..., 0.432]  # 1024ì°¨ì› ë²¡í„°
    }
]
```

## ğŸ”„ í†µì‹  ë°©ì‹

### HTTP REST API
- **í”„ë¡œí† ì½œ**: HTTP/1.1
- **í¬ë§·**: JSON
- **ì¸ì½”ë”©**: UTF-8
- **ë¹„ë™ê¸° ì²˜ë¦¬**: FastAPI + asyncio

### ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™
```python
# PostgreSQL ì—°ê²°
from sqlalchemy.ext.asyncio import create_async_engine
engine = create_async_engine(
    f"postgresql+asyncpg://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}"
)

# Milvus ì—°ê²°
from pymilvus import connections, Collection
connections.connect(
    host=MILVUS_HOST,
    port=MILVUS_INTERNAL_PORT
)
```

### ì„ë² ë”© ëª¨ë¸ ë¡œë”©
```python
from sentence_transformers import SentenceTransformer
import torch

# CUDA ìë™ ê°ì§€
device = "cuda" if torch.cuda.is_available() and USE_CUDA else "cpu"
model = SentenceTransformer(EMBEDDING_MODEL, device=device)
```

## ğŸ”— ì˜ì¡´ì„±

### í•„ìˆ˜ ì˜ì¡´ì„±
```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlalchemy==2.0.23
asyncpg==0.29.0
sentence-transformers==2.2.2
pymilvus==2.3.3
torch==2.1.0
transformers==4.35.2
numpy==1.24.3
```

### CUDA ì˜ì¡´ì„± (GPU ì‚¬ìš© ì‹œ)
```txt
torch==2.1.0+cu121
torchvision==0.16.0+cu121
torchaudio==2.1.0+cu121
```

### ì‹œìŠ¤í…œ ì˜ì¡´ì„±
- **Python 3.11+**
- **CUDA 12.1** (GPU ì‚¬ìš© ì‹œ)
- **PostgreSQL ë°ì´í„°ë² ì´ìŠ¤**: ì œí’ˆ ë°ì´í„° ì¡°íšŒ
- **Milvus ë²¡í„°DB**: ë²¡í„° ì €ì¥

### ì—°ê´€ ì„œë¹„ìŠ¤
- **PostgreSQL DB**: ì›ë³¸ ì œí’ˆ ë°ì´í„° ì†ŒìŠ¤
- **Milvus DB**: ë²¡í„° ë°ì´í„° ì €ì¥ì†Œ
- **Scraper Service**: ìƒˆ ì œí’ˆ ë°ì´í„° ìˆ˜ì§‘ ì‹œ ì¸ë±ì‹± íŠ¸ë¦¬ê±°

## ğŸ§  ì„ë² ë”© ëª¨ë¸ (BGE-M3)

### ëª¨ë¸ íŠ¹ì§•
```python
model_info = {
    "name": "BAAI/bge-m3",
    "type": "multilingual",
    "dimension": 1024,
    "max_length": 8192,
    "languages": ["en", "ko", "zh", "ja", ...],
    "performance": "SOTA on multilingual retrieval tasks"
}
```

### ë²¡í„° ìƒì„± ê³¼ì •
```python
def generate_embeddings(texts: List[str]) -> List[List[float]]:
    # ë°°ì¹˜ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± í–¥ìƒ
    embeddings = model.encode(
        texts,
        batch_size=32,
        show_progress_bar=True,
        convert_to_numpy=True,
        normalize_embeddings=True  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìµœì í™”
    )
    return embeddings.tolist()
```

### GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    
# ë°°ì¹˜ í¬ê¸° ë™ì  ì¡°ì •
max_batch_size = 32 if device == "cuda" else 8
```

## ğŸ“ í…ìŠ¤íŠ¸ ì²­í‚¹ ì „ëµ

### ì œí’ˆë³„ ì²­í‚¹ ë¡œì§
```python
def create_product_chunks(product: dict) -> List[dict]:
    chunks = []
    
    # ì²­í¬ 1: ì œí’ˆëª… + ê¸°ë³¸ ì •ë³´
    chunk1 = f"{product['product_name']} {product.get('color', '')} "
    chunk1 += f"{product['description'].get('kr', '')} {product['description'].get('global', '')}"
    chunks.append({"text": chunk1, "type": "product_basic"})
    
    # ì²­í¬ 2: ì¬ì§ˆ + íŠ¹ì§•
    material_kr = product['material'].get('kr', '')
    material_global = product['material'].get('global', '')
    chunk2 = f"ì¬ì§ˆ: {material_kr} {material_global} ê³ í’ˆì§ˆ ì†Œì¬ ë‚´êµ¬ì„±"
    chunks.append({"text": chunk2, "type": "material_features"})
    
    # ì²­í¬ 3: ì‚¬ì´ì¦ˆ + ê°€ê²©
    size_info = f"ì‚¬ì´ì¦ˆ: {product['size'].get('kr', '')} {product['size'].get('global', '')}"
    price_info = f"ê°€ê²©: {product['price'].get('global', '')} {product['price'].get('kr', '')}"
    chunk3 = f"{size_info} {price_info}"
    chunks.append({"text": chunk3, "type": "size_price"})
    
    return chunks
```

### ì²­í‚¹ ìµœì í™”
- **ìµœëŒ€ ê¸¸ì´**: 4000ì (ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤)
- **ì¤‘ë³µ ì œê±°**: ë™ì¼í•œ ì²­í¬ ë‚´ìš© ì¤‘ë³µ ë°©ì§€
- **ì˜ë¯¸ ë³´ì¡´**: ë¬¸ë§¥ìƒ ì˜ë¯¸ê°€ ëŠì–´ì§€ì§€ ì•Šë„ë¡ ë¶„í• 

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ì²˜ë¦¬ ì„±ëŠ¥
```python
performance_metrics = {
    "cpu_processing": "10-15 products/minute",
    "gpu_processing": "50-100 products/minute",
    "batch_size_optimal": 32,
    "memory_usage": "2-4GB (GPU), 500MB (CPU)"
}
```

### ì—ëŸ¬ ì²˜ë¦¬
```python
try:
    embeddings = model.encode(texts)
    insert_to_milvus(embeddings)
    update_product_indexed_status(product_id, True)
except Exception as e:
    logger.error(f"ì¸ë±ì‹± ì‹¤íŒ¨ (Product ID: {product_id}): {e}")
    update_product_indexed_status(product_id, False)
    raise
```

### ë¡œê¹…
```python
logger.info(f"ì¸ë±ì‹± ì‹œì‘: {total_products}ê°œ ì œí’ˆ")
logger.info(f"ë²¡í„° ìƒì„± ì™„ë£Œ: {len(embeddings)}ê°œ")
logger.info(f"Milvus ì €ì¥ ì™„ë£Œ: {insert_count}ê°œ")
logger.info(f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
```

## âš ï¸ ì£¼ì˜ì‚¬í•­
- **GPU ë©”ëª¨ë¦¬**: ëŒ€ëŸ‰ ì²˜ë¦¬ ì‹œ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì£¼ì˜
- **ëª¨ë¸ ë¡œë”©**: ì´ˆê¸° ëª¨ë¸ ë¡œë”©ì— ì‹œê°„ ì†Œìš” (1-2ë¶„)
- **ë°°ì¹˜ ì²˜ë¦¬**: ë„ˆë¬´ í° ë°°ì¹˜ëŠ” ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš° ìœ„í—˜
- **ì¤‘ë³µ ì¸ë±ì‹±**: ì´ë¯¸ ì¸ë±ì‹±ëœ ì œí’ˆ ì¬ì²˜ë¦¬ ë°©ì§€ ë¡œì§ í•„ìš”
- **ë„¤íŠ¸ì›Œí¬**: Milvus ì—°ê²° ëŠê¹€ ì‹œ ì¬ì—°ê²° ë¡œì§ êµ¬í˜„